{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='clickHouseInstallationTemplate', url='', help='"define a set of Kubernetes resources (StatefulSet, PVC, Service, ConfigMap) which describe behavior one or more ClickHouse clusters"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of ClickHouseInstallationTemplate', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'clickhouse.altinity.com/v1',
    kind: 'ClickHouseInstallationTemplate',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"Specification of the desired behavior of one or more ClickHouse clusters\\nMore info: https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md\\n"'),
  spec: {
    '#configuration':: d.obj(help='"allows configure multiple aspects and behavior for `clickhouse-server` instance and also allows describe multiple `clickhouse-server` clusters inside one `chi` resource"'),
    configuration: {
      '#clusters':: d.obj(help='"describes ClickHouse clusters layout and allows change settings on cluster-level, shard-level and replica-level\\nevery cluster is a set of StatefulSet, one StatefulSet contains only one Pod with `clickhouse-server`\\nall Pods will rendered in <remote_server> part of ClickHouse configs, mounted from ConfigMap as `/etc/clickhouse-server/config.d/chop-generated-remote_servers.xml`\\nClusters will use for Distributed table engine, more details: https://clickhouse.tech/docs/en/engines/table-engines/special/distributed/\\nIf `cluster` contains zookeeper settings (could be inherited from top `chi` level), when you can create *ReplicatedMergeTree tables\\n"'),
      clusters: {
        '#layout':: d.obj(help='"describe current cluster layout, how much shards in cluster, how much replica in shard\\nallows override settings on each shard and replica separatelly\\n"'),
        layout: {
          '#replicas':: d.obj(help='"optional, allows override top-level `chi.spec.configuration` and cluster-level `chi.spec.configuration.clusters` configuration for each replica and each shard relates to selected replica, use it only if you fully understand what you do"'),
          replicas: {
            '#shards':: d.obj(help='"optional, list of shards related to current replica, will ignore if `chi.spec.configuration.clusters.layout.shards` presents"'),
            shards: {
              '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to selected replica\\noverride top-level `chi.spec.configuration.templates`, cluster-level `chi.spec.configuration.clusters.templates`, replica-level `chi.spec.configuration.clusters.layout.replicas.templates`\\n"'),
              templates: {
                '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
                withClusterServiceTemplate(clusterServiceTemplate): { templates+: { clusterServiceTemplate: clusterServiceTemplate } },
                '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
                withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } },
                '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
                withHostTemplate(hostTemplate): { templates+: { hostTemplate: hostTemplate } },
                '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
                withLogVolumeClaimTemplate(logVolumeClaimTemplate): { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } },
                '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
                withPodTemplate(podTemplate): { templates+: { podTemplate: podTemplate } },
                '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
                withReplicaServiceTemplate(replicaServiceTemplate): { templates+: { replicaServiceTemplate: replicaServiceTemplate } },
                '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
                withServiceTemplate(serviceTemplate): { templates+: { serviceTemplate: serviceTemplate } },
                '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
                withShardServiceTemplate(shardServiceTemplate): { templates+: { shardServiceTemplate: shardServiceTemplate } },
                '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
                withVolumeClaimTemplate(volumeClaimTemplate): { templates+: { volumeClaimTemplate: volumeClaimTemplate } },
              },
              '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one shard related to current replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`, will ignore if `chi.spec.configuration.clusters.layout.shards` presents\\n"', args=[d.arg(name='files', type=d.T.object)]),
              withFiles(files): { files: files },
              '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one shard related to current replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`, will ignore if `chi.spec.configuration.clusters.layout.shards` presents\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
              withFilesMixin(files): { files+: files },
              '#withHttpPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `http` for selected shard, override `chi.spec.templates.hostTemplates.spec.httpPort`\\nallows connect to `clickhouse-server` via HTTP protocol via kubernetes `Service`\\n"', args=[d.arg(name='httpPort', type=d.T.integer)]),
              withHttpPort(httpPort): { httpPort: httpPort },
              '#withHttpsPort':: d.fn(help='', args=[d.arg(name='httpsPort', type=d.T.integer)]),
              withHttpsPort(httpsPort): { httpsPort: httpsPort },
              '#withInsecure':: d.fn(help='"optional, open insecure ports for cluster, defaults to \\"yes\\"\\n"', args=[d.arg(name='insecure', type=d.T.string)]),
              withInsecure(insecure): { insecure: insecure },
              '#withInterserverHTTPPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `interserver` for selected shard, override `chi.spec.templates.hostTemplates.spec.interserverHTTPPort`\\nallows connect between replicas inside same shard during fetch replicated data parts HTTP protocol\\n"', args=[d.arg(name='interserverHTTPPort', type=d.T.integer)]),
              withInterserverHTTPPort(interserverHTTPPort): { interserverHTTPPort: interserverHTTPPort },
              '#withName':: d.fn(help='"optional, by default shard name is generated, but you can override it and setup custom name"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withSecure':: d.fn(help='"optional, open secure ports\\n"', args=[d.arg(name='secure', type=d.T.string)]),
              withSecure(secure): { secure: secure },
              '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one shard related to current replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and replica-level `chi.spec.configuration.clusters.layout.replicas.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
              withSettings(settings): { settings: settings },
              '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one shard related to current replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and replica-level `chi.spec.configuration.clusters.layout.replicas.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
              withSettingsMixin(settings): { settings+: settings },
              '#withTcpPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `tcp` for selected shard, override `chi.spec.templates.hostTemplates.spec.tcpPort`\\nallows connect to `clickhouse-server` via TCP Native protocol via kubernetes `Service`\\n"', args=[d.arg(name='tcpPort', type=d.T.integer)]),
              withTcpPort(tcpPort): { tcpPort: tcpPort },
              '#withTlsPort':: d.fn(help='', args=[d.arg(name='tlsPort', type=d.T.integer)]),
              withTlsPort(tlsPort): { tlsPort: tlsPort },
            },
            '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to selected replica\\noverride top-level `chi.spec.configuration.templates`, cluster-level `chi.spec.configuration.clusters.templates`\\n"'),
            templates: {
              '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
              withClusterServiceTemplate(clusterServiceTemplate): { templates+: { clusterServiceTemplate: clusterServiceTemplate } },
              '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
              withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } },
              '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
              withHostTemplate(hostTemplate): { templates+: { hostTemplate: hostTemplate } },
              '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
              withLogVolumeClaimTemplate(logVolumeClaimTemplate): { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } },
              '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
              withPodTemplate(podTemplate): { templates+: { podTemplate: podTemplate } },
              '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
              withReplicaServiceTemplate(replicaServiceTemplate): { templates+: { replicaServiceTemplate: replicaServiceTemplate } },
              '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
              withServiceTemplate(serviceTemplate): { templates+: { serviceTemplate: serviceTemplate } },
              '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
              withShardServiceTemplate(shardServiceTemplate): { templates+: { shardServiceTemplate: shardServiceTemplate } },
              '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
              withVolumeClaimTemplate(volumeClaimTemplate): { templates+: { volumeClaimTemplate: volumeClaimTemplate } },
            },
            '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`, will ignore if `chi.spec.configuration.clusters.layout.shards` presents\\n"', args=[d.arg(name='files', type=d.T.object)]),
            withFiles(files): { files: files },
            '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`, will ignore if `chi.spec.configuration.clusters.layout.shards` presents\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
            withFilesMixin(files): { files+: files },
            '#withName':: d.fn(help='"optional, by default replica name is generated, but you can override it and setup custom name"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and will ignore if shard-level `chi.spec.configuration.clusters.layout.shards` present\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
            withSettings(settings): { settings: settings },
            '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and will ignore if shard-level `chi.spec.configuration.clusters.layout.shards` present\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
            withSettingsMixin(settings): { settings+: settings },
            '#withShards':: d.fn(help='"optional, list of shards related to current replica, will ignore if `chi.spec.configuration.clusters.layout.shards` presents"', args=[d.arg(name='shards', type=d.T.array)]),
            withShards(shards): { shards: if std.isArray(v=shards) then shards else [shards] },
            '#withShardsCount':: d.fn(help='"optional, count of shards related to current replica, you can override each shard behavior on low-level `chi.spec.configuration.clusters.layout.replicas.shards`"', args=[d.arg(name='shardsCount', type=d.T.integer)]),
            withShardsCount(shardsCount): { shardsCount: shardsCount },
            '#withShardsMixin':: d.fn(help='"optional, list of shards related to current replica, will ignore if `chi.spec.configuration.clusters.layout.shards` presents"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='shards', type=d.T.array)]),
            withShardsMixin(shards): { shards+: if std.isArray(v=shards) then shards else [shards] },
          },
          '#shards':: d.obj(help='"optional, allows override top-level `chi.spec.configuration`, cluster-level `chi.spec.configuration.clusters` settings for each shard separately, use it only if you fully understand what you do"'),
          shards: {
            '#replicas':: d.obj(help='"optional, allows override behavior for selected replicas from cluster-level `chi.spec.configuration.clusters` and shard-level `chi.spec.configuration.clusters.layout.shards`\\n"'),
            replicas: {
              '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to selected replica\\noverride top-level `chi.spec.configuration.templates`, cluster-level `chi.spec.configuration.clusters.templates` and shard-level `chi.spec.configuration.clusters.layout.shards.templates`\\n"'),
              templates: {
                '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
                withClusterServiceTemplate(clusterServiceTemplate): { templates+: { clusterServiceTemplate: clusterServiceTemplate } },
                '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
                withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } },
                '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
                withHostTemplate(hostTemplate): { templates+: { hostTemplate: hostTemplate } },
                '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
                withLogVolumeClaimTemplate(logVolumeClaimTemplate): { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } },
                '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
                withPodTemplate(podTemplate): { templates+: { podTemplate: podTemplate } },
                '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
                withReplicaServiceTemplate(replicaServiceTemplate): { templates+: { replicaServiceTemplate: replicaServiceTemplate } },
                '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
                withServiceTemplate(serviceTemplate): { templates+: { serviceTemplate: serviceTemplate } },
                '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
                withShardServiceTemplate(shardServiceTemplate): { templates+: { shardServiceTemplate: shardServiceTemplate } },
                '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
                withVolumeClaimTemplate(volumeClaimTemplate): { templates+: { volumeClaimTemplate: volumeClaimTemplate } },
              },
              '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files`, cluster-level `chi.spec.configuration.clusters.files` and shard-level `chi.spec.configuration.clusters.layout.shards.files`\\n"', args=[d.arg(name='files', type=d.T.object)]),
              withFiles(files): { files: files },
              '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files`, cluster-level `chi.spec.configuration.clusters.files` and shard-level `chi.spec.configuration.clusters.layout.shards.files`\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
              withFilesMixin(files): { files+: files },
              '#withHttpPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `http` for selected replica, override `chi.spec.templates.hostTemplates.spec.httpPort`\\nallows connect to `clickhouse-server` via HTTP protocol via kubernetes `Service`\\n"', args=[d.arg(name='httpPort', type=d.T.integer)]),
              withHttpPort(httpPort): { httpPort: httpPort },
              '#withHttpsPort':: d.fn(help='', args=[d.arg(name='httpsPort', type=d.T.integer)]),
              withHttpsPort(httpsPort): { httpsPort: httpsPort },
              '#withInsecure':: d.fn(help='"optional, open insecure ports for cluster, defaults to \\"yes\\"\\n"', args=[d.arg(name='insecure', type=d.T.string)]),
              withInsecure(insecure): { insecure: insecure },
              '#withInterserverHTTPPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `interserver` for selected replica, override `chi.spec.templates.hostTemplates.spec.interserverHTTPPort`\\nallows connect between replicas inside same shard during fetch replicated data parts HTTP protocol\\n"', args=[d.arg(name='interserverHTTPPort', type=d.T.integer)]),
              withInterserverHTTPPort(interserverHTTPPort): { interserverHTTPPort: interserverHTTPPort },
              '#withName':: d.fn(help='"optional, by default replica name is generated, but you can override it and setup custom name"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withSecure':: d.fn(help='"optional, open secure ports\\n"', args=[d.arg(name='secure', type=d.T.string)]),
              withSecure(secure): { secure: secure },
              '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and shard-level `chi.spec.configuration.clusters.layout.shards.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
              withSettings(settings): { settings: settings },
              '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in `Pod` only in one replica during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\noverride top-level `chi.spec.configuration.settings`, cluster-level `chi.spec.configuration.clusters.settings` and shard-level `chi.spec.configuration.clusters.layout.shards.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
              withSettingsMixin(settings): { settings+: settings },
              '#withTcpPort':: d.fn(help='"optional, setup `Pod.spec.containers.ports` with name `tcp` for selected replica, override `chi.spec.templates.hostTemplates.spec.tcpPort`\\nallows connect to `clickhouse-server` via TCP Native protocol via kubernetes `Service`\\n"', args=[d.arg(name='tcpPort', type=d.T.integer)]),
              withTcpPort(tcpPort): { tcpPort: tcpPort },
              '#withTlsPort':: d.fn(help='', args=[d.arg(name='tlsPort', type=d.T.integer)]),
              withTlsPort(tlsPort): { tlsPort: tlsPort },
            },
            '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to selected shard\\noverride top-level `chi.spec.configuration.templates` and cluster-level `chi.spec.configuration.clusters.templates`\\n"'),
            templates: {
              '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
              withClusterServiceTemplate(clusterServiceTemplate): { templates+: { clusterServiceTemplate: clusterServiceTemplate } },
              '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
              withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } },
              '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
              withHostTemplate(hostTemplate): { templates+: { hostTemplate: hostTemplate } },
              '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
              withLogVolumeClaimTemplate(logVolumeClaimTemplate): { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } },
              '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
              withPodTemplate(podTemplate): { templates+: { podTemplate: podTemplate } },
              '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
              withReplicaServiceTemplate(replicaServiceTemplate): { templates+: { replicaServiceTemplate: replicaServiceTemplate } },
              '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
              withServiceTemplate(serviceTemplate): { templates+: { serviceTemplate: serviceTemplate } },
              '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
              withShardServiceTemplate(shardServiceTemplate): { templates+: { shardServiceTemplate: shardServiceTemplate } },
              '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
              withVolumeClaimTemplate(volumeClaimTemplate): { templates+: { volumeClaimTemplate: volumeClaimTemplate } },
            },
            '#withDefinitionType':: d.fn(help='"DEPRECATED - to be removed soon"', args=[d.arg(name='definitionType', type=d.T.string)]),
            withDefinitionType(definitionType): { definitionType: definitionType },
            '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one shard during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`\\n"', args=[d.arg(name='files', type=d.T.object)]),
            withFiles(files): { files: files },
            '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` only in one shard during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files` and cluster-level `chi.spec.configuration.clusters.files`\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
            withFilesMixin(files): { files+: files },
            '#withInternalReplication':: d.fn(help='"optional, `true` by default when `chi.spec.configuration.clusters[].layout.ReplicaCount` > 1 and 0 otherwise\\nallows setup <internal_replication> setting which will use during insert into tables with `Distributed` engine for insert only in one live replica and other replicas will download inserted data during replication,\\nwill apply in <remote_servers> inside ConfigMap which will mount in /etc/clickhouse-server/config.d/chop-generated-remote_servers.xml\\nMore details: https://clickhouse.tech/docs/en/engines/table-engines/special/distributed/\\n"', args=[d.arg(name='internalReplication', type=d.T.string)]),
            withInternalReplication(internalReplication): { internalReplication: internalReplication },
            '#withName':: d.fn(help='"optional, by default shard name is generated, but you can override it and setup custom name"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withReplicas':: d.fn(help='"optional, allows override behavior for selected replicas from cluster-level `chi.spec.configuration.clusters` and shard-level `chi.spec.configuration.clusters.layout.shards`\\n"', args=[d.arg(name='replicas', type=d.T.array)]),
            withReplicas(replicas): { replicas: if std.isArray(v=replicas) then replicas else [replicas] },
            '#withReplicasCount':: d.fn(help='"optional, how much replicas in selected shard for selected ClickHouse cluster will run in Kubernetes, each replica is a separate `StatefulSet` which contains only one `Pod` with `clickhouse-server` instance,\\nshard contains 1 replica by default\\noverride cluster-level `chi.spec.configuration.clusters.layout.replicasCount`\\n"', args=[d.arg(name='replicasCount', type=d.T.integer)]),
            withReplicasCount(replicasCount): { replicasCount: replicasCount },
            '#withReplicasMixin':: d.fn(help='"optional, allows override behavior for selected replicas from cluster-level `chi.spec.configuration.clusters` and shard-level `chi.spec.configuration.clusters.layout.shards`\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='replicas', type=d.T.array)]),
            withReplicasMixin(replicas): { replicas+: if std.isArray(v=replicas) then replicas else [replicas] },
            '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` only in one shard during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\noverride top-level `chi.spec.configuration.settings` and cluster-level `chi.spec.configuration.clusters.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
            withSettings(settings): { settings: settings },
            '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` only in one shard during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\noverride top-level `chi.spec.configuration.settings` and cluster-level `chi.spec.configuration.clusters.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
            withSettingsMixin(settings): { settings+: settings },
            '#withWeight':: d.fn(help='"optional, 1 by default, allows setup shard <weight> setting which will use during insert into tables with `Distributed` engine,\\nwill apply in <remote_servers> inside ConfigMap which will mount in /etc/clickhouse-server/config.d/chop-generated-remote_servers.xml\\nMore details: https://clickhouse.tech/docs/en/engines/table-engines/special/distributed/\\n"', args=[d.arg(name='weight', type=d.T.integer)]),
            withWeight(weight): { weight: weight },
          },
          '#withReplicas':: d.fn(help='"optional, allows override top-level `chi.spec.configuration` and cluster-level `chi.spec.configuration.clusters` configuration for each replica and each shard relates to selected replica, use it only if you fully understand what you do"', args=[d.arg(name='replicas', type=d.T.array)]),
          withReplicas(replicas): { layout+: { replicas: if std.isArray(v=replicas) then replicas else [replicas] } },
          '#withReplicasCount':: d.fn(help='"how much replicas in each shards for current ClickHouse cluster will run in Kubernetes, each replica is a separate `StatefulSet` which contains only one `Pod` with `clickhouse-server` instance, every shard contains 1 replica by default"', args=[d.arg(name='replicasCount', type=d.T.integer)]),
          withReplicasCount(replicasCount): { layout+: { replicasCount: replicasCount } },
          '#withReplicasMixin':: d.fn(help='"optional, allows override top-level `chi.spec.configuration` and cluster-level `chi.spec.configuration.clusters` configuration for each replica and each shard relates to selected replica, use it only if you fully understand what you do"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='replicas', type=d.T.array)]),
          withReplicasMixin(replicas): { layout+: { replicas+: if std.isArray(v=replicas) then replicas else [replicas] } },
          '#withShards':: d.fn(help='"optional, allows override top-level `chi.spec.configuration`, cluster-level `chi.spec.configuration.clusters` settings for each shard separately, use it only if you fully understand what you do"', args=[d.arg(name='shards', type=d.T.array)]),
          withShards(shards): { layout+: { shards: if std.isArray(v=shards) then shards else [shards] } },
          '#withShardsCount':: d.fn(help='"how much shards for current ClickHouse cluster will run in Kubernetes, each shard contains shared-nothing part of data and contains set of replicas, cluster contains 1 shard by default"', args=[d.arg(name='shardsCount', type=d.T.integer)]),
          withShardsCount(shardsCount): { layout+: { shardsCount: shardsCount } },
          '#withShardsMixin':: d.fn(help='"optional, allows override top-level `chi.spec.configuration`, cluster-level `chi.spec.configuration.clusters` settings for each shard separately, use it only if you fully understand what you do"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='shards', type=d.T.array)]),
          withShardsMixin(shards): { layout+: { shards+: if std.isArray(v=shards) then shards else [shards] } },
          '#withType':: d.fn(help='"DEPRECATED - to be removed soon"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { layout+: { type: type } },
        },
        '#schemaPolicy':: d.obj(help='"describes how schema is propagated within replicas and shards\\n"'),
        schemaPolicy: {
          '#withReplica':: d.fn(help='"how schema is propagated within a replica"', args=[d.arg(name='replica', type=d.T.string)]),
          withReplica(replica): { schemaPolicy+: { replica: replica } },
          '#withShard':: d.fn(help='"how schema is propagated between shards"', args=[d.arg(name='shard', type=d.T.string)]),
          withShard(shard): { schemaPolicy+: { shard: shard } },
        },
        '#secret':: d.obj(help='"optional, shared secret value to secure cluster communications"'),
        secret: {
          '#valueFrom':: d.obj(help='"Cluster shared secret source"'),
          valueFrom: {
            '#secretKeyRef':: d.obj(help='"Selects a key of a secret in the clickhouse installation namespace.\\nShould not be used if value is not empty.\\n"'),
            secretKeyRef: {
              '#withKey':: d.fn(help='"The key of the secret to select from. Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { secret+: { valueFrom+: { secretKeyRef+: { key: key } } } },
              '#withName':: d.fn(help='"Name of the referent. More info:\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\\n"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { secret+: { valueFrom+: { secretKeyRef+: { name: name } } } },
              '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { secret+: { valueFrom+: { secretKeyRef+: { optional: optional } } } },
            },
          },
          '#withAuto':: d.fn(help='"Auto-generate shared secret value to secure cluster communications"', args=[d.arg(name='auto', type=d.T.string)]),
          withAuto(auto): { secret+: { auto: auto } },
          '#withValue':: d.fn(help='"Cluster shared secret value in plain text"', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { secret+: { value: value } },
        },
        '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to selected cluster\\noverride top-level `chi.spec.configuration.templates`\\n"'),
        templates: {
          '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
          withClusterServiceTemplate(clusterServiceTemplate): { templates+: { clusterServiceTemplate: clusterServiceTemplate } },
          '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
          withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } },
          '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
          withHostTemplate(hostTemplate): { templates+: { hostTemplate: hostTemplate } },
          '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
          withLogVolumeClaimTemplate(logVolumeClaimTemplate): { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } },
          '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
          withPodTemplate(podTemplate): { templates+: { podTemplate: podTemplate } },
          '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
          withReplicaServiceTemplate(replicaServiceTemplate): { templates+: { replicaServiceTemplate: replicaServiceTemplate } },
          '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
          withServiceTemplate(serviceTemplate): { templates+: { serviceTemplate: serviceTemplate } },
          '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
          withShardServiceTemplate(shardServiceTemplate): { templates+: { shardServiceTemplate: shardServiceTemplate } },
          '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
          withVolumeClaimTemplate(volumeClaimTemplate): { templates+: { volumeClaimTemplate: volumeClaimTemplate } },
        },
        '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` on current cluster during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files`\\n"', args=[d.arg(name='files', type=d.T.object)]),
        withFiles(files): { files: files },
        '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` on current cluster during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\noverride top-level `chi.spec.configuration.files`\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
        withFilesMixin(files): { files+: files },
        '#withInsecure':: d.fn(help='"optional, open insecure ports for cluster, defaults to \\"yes\\', args=[d.arg(name='insecure', type=d.T.string)]),
        withInsecure(insecure): { insecure: insecure },
        '#withName':: d.fn(help='"cluster name, used to identify set of ClickHouse servers and wide used during generate names of related Kubernetes resources"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withSecure':: d.fn(help='"optional, open secure ports for cluster"', args=[d.arg(name='secure', type=d.T.string)]),
        withSecure(secure): { secure: secure },
        '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` only in one cluster during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\noverride top-level `chi.spec.configuration.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
        withSettings(settings): { settings: settings },
        '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` only in one cluster during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\noverride top-level `chi.spec.configuration.settings`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
        withSettingsMixin(settings): { settings+: settings },
        '#zookeeper':: d.obj(help='"optional, allows configure <yandex><zookeeper>..</zookeeper></yandex> section in each `Pod` only in current ClickHouse cluster, during generate `ConfigMap` which will mounted in `/etc/clickhouse-server/config.d/`\\noverride top-level `chi.spec.configuration.zookeeper` settings\\n"'),
        zookeeper: {
          '#nodes':: d.obj(help='"describe every available zookeeper cluster node for interaction"'),
          nodes: {
            '#withHost':: d.fn(help='"dns name or ip address for Zookeeper node"', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { host: host },
            '#withPort':: d.fn(help='"TCP port which used to connect to Zookeeper node"', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { port: port },
            '#withSecure':: d.fn(help='"if a secure connection to Zookeeper is required"', args=[d.arg(name='secure', type=d.T.string)]),
            withSecure(secure): { secure: secure },
          },
          '#withIdentity':: d.fn(help='"optional access credentials string with `user:password` format used when use digest authorization in Zookeeper"', args=[d.arg(name='identity', type=d.T.string)]),
          withIdentity(identity): { zookeeper+: { identity: identity } },
          '#withNodes':: d.fn(help='"describe every available zookeeper cluster node for interaction"', args=[d.arg(name='nodes', type=d.T.array)]),
          withNodes(nodes): { zookeeper+: { nodes: if std.isArray(v=nodes) then nodes else [nodes] } },
          '#withNodesMixin':: d.fn(help='"describe every available zookeeper cluster node for interaction"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodes', type=d.T.array)]),
          withNodesMixin(nodes): { zookeeper+: { nodes+: if std.isArray(v=nodes) then nodes else [nodes] } },
          '#withOperation_timeout_ms':: d.fn(help='"one operation timeout during Zookeeper transactions"', args=[d.arg(name='operation_timeout_ms', type=d.T.integer)]),
          withOperation_timeout_ms(operation_timeout_ms): { zookeeper+: { operation_timeout_ms: operation_timeout_ms } },
          '#withRoot':: d.fn(help='"optional root znode path inside zookeeper to store ClickHouse related data (replication queue or distributed DDL)"', args=[d.arg(name='root', type=d.T.string)]),
          withRoot(root): { zookeeper+: { root: root } },
          '#withSession_timeout_ms':: d.fn(help='"session timeout during connect to Zookeeper"', args=[d.arg(name='session_timeout_ms', type=d.T.integer)]),
          withSession_timeout_ms(session_timeout_ms): { zookeeper+: { session_timeout_ms: session_timeout_ms } },
        },
      },
      '#withClusters':: d.fn(help='"describes ClickHouse clusters layout and allows change settings on cluster-level, shard-level and replica-level\\nevery cluster is a set of StatefulSet, one StatefulSet contains only one Pod with `clickhouse-server`\\nall Pods will rendered in <remote_server> part of ClickHouse configs, mounted from ConfigMap as `/etc/clickhouse-server/config.d/chop-generated-remote_servers.xml`\\nClusters will use for Distributed table engine, more details: https://clickhouse.tech/docs/en/engines/table-engines/special/distributed/\\nIf `cluster` contains zookeeper settings (could be inherited from top `chi` level), when you can create *ReplicatedMergeTree tables\\n"', args=[d.arg(name='clusters', type=d.T.array)]),
      withClusters(clusters): { spec+: { configuration+: { clusters: if std.isArray(v=clusters) then clusters else [clusters] } } },
      '#withClustersMixin':: d.fn(help='"describes ClickHouse clusters layout and allows change settings on cluster-level, shard-level and replica-level\\nevery cluster is a set of StatefulSet, one StatefulSet contains only one Pod with `clickhouse-server`\\nall Pods will rendered in <remote_server> part of ClickHouse configs, mounted from ConfigMap as `/etc/clickhouse-server/config.d/chop-generated-remote_servers.xml`\\nClusters will use for Distributed table engine, more details: https://clickhouse.tech/docs/en/engines/table-engines/special/distributed/\\nIf `cluster` contains zookeeper settings (could be inherited from top `chi` level), when you can create *ReplicatedMergeTree tables\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusters', type=d.T.array)]),
      withClustersMixin(clusters): { spec+: { configuration+: { clusters+: if std.isArray(v=clusters) then clusters else [clusters] } } },
      '#withFiles':: d.fn(help='"allows define content of any setting file inside each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\nevery key in this object is the file name\\nevery value in this object is the file content\\nyou can use `!!binary |` and base64 for binary files, see details here https://yaml.org/type/binary.html\\neach key could contains prefix like USERS, COMMON, HOST or config.d, users.d, cond.d, wrong prefixes will ignored, subfolders also will ignored\\nMore details: https://github.com/Altinity/clickhouse-operator/blob/master/docs/chi-examples/05-settings-05-files-nested.yaml\\n"', args=[d.arg(name='files', type=d.T.object)]),
      withFiles(files): { spec+: { configuration+: { files: files } } },
      '#withFilesMixin':: d.fn(help='"allows define content of any setting file inside each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\nevery key in this object is the file name\\nevery value in this object is the file content\\nyou can use `!!binary |` and base64 for binary files, see details here https://yaml.org/type/binary.html\\neach key could contains prefix like USERS, COMMON, HOST or config.d, users.d, cond.d, wrong prefixes will ignored, subfolders also will ignored\\nMore details: https://github.com/Altinity/clickhouse-operator/blob/master/docs/chi-examples/05-settings-05-files-nested.yaml\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
      withFilesMixin(files): { spec+: { configuration+: { files+: files } } },
      '#withProfiles':: d.fn(help='"allows configure <yandex><profiles>..</profiles></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure any aspect of settings profile\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings-profiles/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationprofiles\\n"', args=[d.arg(name='profiles', type=d.T.object)]),
      withProfiles(profiles): { spec+: { configuration+: { profiles: profiles } } },
      '#withProfilesMixin':: d.fn(help='"allows configure <yandex><profiles>..</profiles></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure any aspect of settings profile\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings-profiles/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationprofiles\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='profiles', type=d.T.object)]),
      withProfilesMixin(profiles): { spec+: { configuration+: { profiles+: profiles } } },
      '#withQuotas':: d.fn(help='"allows configure <yandex><quotas>..</quotas></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure any aspect of resource quotas\\nMore details: https://clickhouse.tech/docs/en/operations/quotas/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationquotas\\n"', args=[d.arg(name='quotas', type=d.T.object)]),
      withQuotas(quotas): { spec+: { configuration+: { quotas: quotas } } },
      '#withQuotasMixin':: d.fn(help='"allows configure <yandex><quotas>..</quotas></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure any aspect of resource quotas\\nMore details: https://clickhouse.tech/docs/en/operations/quotas/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationquotas\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='quotas', type=d.T.object)]),
      withQuotasMixin(quotas): { spec+: { configuration+: { quotas+: quotas } } },
      '#withSettings':: d.fn(help='"allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationsettings\\n"', args=[d.arg(name='settings', type=d.T.object)]),
      withSettings(settings): { spec+: { configuration+: { settings: settings } } },
      '#withSettingsMixin':: d.fn(help='"allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationsettings\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
      withSettingsMixin(settings): { spec+: { configuration+: { settings+: settings } } },
      '#withUsers':: d.fn(help='"allows configure <yandex><users>..</users></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure password hashed, authorization restrictions, database level security row filters etc.\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings-users/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationusers\\n"', args=[d.arg(name='users', type=d.T.object)]),
      withUsers(users): { spec+: { configuration+: { users: users } } },
      '#withUsersMixin':: d.fn(help='"allows configure <yandex><users>..</users></yandex> section in each `Pod` during generate `ConfigMap` which will mount in `/etc/clickhouse-server/users.d/`\\nyou can configure password hashed, authorization restrictions, database level security row filters etc.\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings-users/\\nYour yaml code will convert to XML, see examples https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationusers\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='users', type=d.T.object)]),
      withUsersMixin(users): { spec+: { configuration+: { users+: users } } },
      '#zookeeper':: d.obj(help="\"allows configure \u003cyandex\u003e\u003czookeeper\u003e..\u003c/zookeeper\u003e\u003c/yandex\u003e section in each `Pod` during generate `ConfigMap` which will mounted in `/etc/clickhouse-server/config.d/`\\n`clickhouse-operator` itself doesn't manage Zookeeper, please install Zookeeper separatelly look examples on https://github.com/Altinity/clickhouse-operator/tree/master/deploy/zookeeper/\\ncurrently, zookeeper (or clickhouse-keeper replacement) used for *ReplicatedMergeTree table engines and for `distributed_ddl`\\nMore details: https://clickhouse.tech/docs/en/operations/server-configuration-parameters/settings/#server-settings_zookeeper\\n\""),
      zookeeper: {
        '#nodes':: d.obj(help='"describe every available zookeeper cluster node for interaction"'),
        nodes: {
          '#withHost':: d.fn(help='"dns name or ip address for Zookeeper node"', args=[d.arg(name='host', type=d.T.string)]),
          withHost(host): { host: host },
          '#withPort':: d.fn(help='"TCP port which used to connect to Zookeeper node"', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { port: port },
          '#withSecure':: d.fn(help='"if a secure connection to Zookeeper is required"', args=[d.arg(name='secure', type=d.T.string)]),
          withSecure(secure): { secure: secure },
        },
        '#withIdentity':: d.fn(help='"optional access credentials string with `user:password` format used when use digest authorization in Zookeeper"', args=[d.arg(name='identity', type=d.T.string)]),
        withIdentity(identity): { spec+: { configuration+: { zookeeper+: { identity: identity } } } },
        '#withNodes':: d.fn(help='"describe every available zookeeper cluster node for interaction"', args=[d.arg(name='nodes', type=d.T.array)]),
        withNodes(nodes): { spec+: { configuration+: { zookeeper+: { nodes: if std.isArray(v=nodes) then nodes else [nodes] } } } },
        '#withNodesMixin':: d.fn(help='"describe every available zookeeper cluster node for interaction"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodes', type=d.T.array)]),
        withNodesMixin(nodes): { spec+: { configuration+: { zookeeper+: { nodes+: if std.isArray(v=nodes) then nodes else [nodes] } } } },
        '#withOperation_timeout_ms':: d.fn(help='"one operation timeout during Zookeeper transactions"', args=[d.arg(name='operation_timeout_ms', type=d.T.integer)]),
        withOperation_timeout_ms(operation_timeout_ms): { spec+: { configuration+: { zookeeper+: { operation_timeout_ms: operation_timeout_ms } } } },
        '#withRoot':: d.fn(help='"optional root znode path inside zookeeper to store ClickHouse related data (replication queue or distributed DDL)"', args=[d.arg(name='root', type=d.T.string)]),
        withRoot(root): { spec+: { configuration+: { zookeeper+: { root: root } } } },
        '#withSession_timeout_ms':: d.fn(help='"session timeout during connect to Zookeeper"', args=[d.arg(name='session_timeout_ms', type=d.T.integer)]),
        withSession_timeout_ms(session_timeout_ms): { spec+: { configuration+: { zookeeper+: { session_timeout_ms: session_timeout_ms } } } },
      },
    },
    '#defaults':: d.obj(help='"define default behavior for whole ClickHouseInstallation, some behavior can be re-define on cluster, shard and replica level\\nMore info: https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specdefaults\\n"'),
    defaults: {
      '#distributedDDL':: d.obj(help='"allows change `<yandex><distributed_ddl></distributed_ddl></yandex>` settings\\nMore info: https://clickhouse.tech/docs/en/operations/server-configuration-parameters/settings/#server-settings-distributed_ddl\\n"'),
      distributedDDL: {
        '#withProfile':: d.fn(help='"Settings from this profile will be used to execute DDL queries"', args=[d.arg(name='profile', type=d.T.string)]),
        withProfile(profile): { spec+: { defaults+: { distributedDDL+: { profile: profile } } } },
      },
      '#storageManagement':: d.obj(help='"default storage management options"'),
      storageManagement: {
        '#withProvisioner':: d.fn(help='"defines `PVC` provisioner - be it StatefulSet or the Operator"', args=[d.arg(name='provisioner', type=d.T.string)]),
        withProvisioner(provisioner): { spec+: { defaults+: { storageManagement+: { provisioner: provisioner } } } },
        '#withReclaimPolicy':: d.fn(help='"defines behavior of `PVC` deletion.\\n`Delete` by default, if `Retain` specified then `PVC` will be kept when deleting StatefulSet\\n"', args=[d.arg(name='reclaimPolicy', type=d.T.string)]),
        withReclaimPolicy(reclaimPolicy): { spec+: { defaults+: { storageManagement+: { reclaimPolicy: reclaimPolicy } } } },
      },
      '#templates':: d.obj(help='"optional, configuration of the templates names which will use for generate Kubernetes resources according to one or more ClickHouse clusters described in current ClickHouseInstallation (chi) resource"'),
      templates: {
        '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
        withClusterServiceTemplate(clusterServiceTemplate): { spec+: { defaults+: { templates+: { clusterServiceTemplate: clusterServiceTemplate } } } },
        '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
        withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { spec+: { defaults+: { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } } } },
        '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
        withHostTemplate(hostTemplate): { spec+: { defaults+: { templates+: { hostTemplate: hostTemplate } } } },
        '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
        withLogVolumeClaimTemplate(logVolumeClaimTemplate): { spec+: { defaults+: { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } } } },
        '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
        withPodTemplate(podTemplate): { spec+: { defaults+: { templates+: { podTemplate: podTemplate } } } },
        '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
        withReplicaServiceTemplate(replicaServiceTemplate): { spec+: { defaults+: { templates+: { replicaServiceTemplate: replicaServiceTemplate } } } },
        '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
        withServiceTemplate(serviceTemplate): { spec+: { defaults+: { templates+: { serviceTemplate: serviceTemplate } } } },
        '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
        withShardServiceTemplate(shardServiceTemplate): { spec+: { defaults+: { templates+: { shardServiceTemplate: shardServiceTemplate } } } },
        '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
        withVolumeClaimTemplate(volumeClaimTemplate): { spec+: { defaults+: { templates+: { volumeClaimTemplate: volumeClaimTemplate } } } },
      },
      '#withReplicasUseFQDN':: d.fn(help='"define should replicas be specified by FQDN in `<host></host>`.\\nIn case of \\"no\\" will use short hostname and clickhouse-server will use kubernetes default suffixes for DNS lookup\\n\\"yes\\" by default\\n"', args=[d.arg(name='replicasUseFQDN', type=d.T.string)]),
      withReplicasUseFQDN(replicasUseFQDN): { spec+: { defaults+: { replicasUseFQDN: replicasUseFQDN } } },
    },
    '#reconciling':: d.obj(help='"optional, allows tuning reconciling cycle for ClickhouseInstallation from clickhouse-operator side"'),
    reconciling: {
      '#cleanup':: d.obj(help='"optional, define behavior for cleanup Kubernetes resources during reconcile cycle"'),
      cleanup: {
        '#reconcileFailedObjects':: d.obj(help='"what clickhouse-operator shall do when reconciling Kubernetes resources are failed, default behavior is `Retain`"'),
        reconcileFailedObjects: {
          '#withConfigMap':: d.fn(help='"behavior policy for failed ConfigMap reconciling, Retain by default"', args=[d.arg(name='configMap', type=d.T.string)]),
          withConfigMap(configMap): { spec+: { reconciling+: { cleanup+: { reconcileFailedObjects+: { configMap: configMap } } } } },
          '#withPvc':: d.fn(help='"behavior policy for failed PVC reconciling, Retain by default"', args=[d.arg(name='pvc', type=d.T.string)]),
          withPvc(pvc): { spec+: { reconciling+: { cleanup+: { reconcileFailedObjects+: { pvc: pvc } } } } },
          '#withService':: d.fn(help='"behavior policy for failed Service reconciling, Retain by default"', args=[d.arg(name='service', type=d.T.string)]),
          withService(service): { spec+: { reconciling+: { cleanup+: { reconcileFailedObjects+: { service: service } } } } },
          '#withStatefulSet':: d.fn(help='"behavior policy for failed StatefulSet reconciling, Retain by default"', args=[d.arg(name='statefulSet', type=d.T.string)]),
          withStatefulSet(statefulSet): { spec+: { reconciling+: { cleanup+: { reconcileFailedObjects+: { statefulSet: statefulSet } } } } },
        },
        '#unknownObjects':: d.obj(help='"what clickhouse-operator shall do when found Kubernetes resources which should be managed with clickhouse-operator, but not have `ownerReference` to any currently managed `ClickHouseInstallation` resource, default behavior is `Delete`"'),
        unknownObjects: {
          '#withConfigMap':: d.fn(help='"behavior policy for unknown ConfigMap, Delete by default"', args=[d.arg(name='configMap', type=d.T.string)]),
          withConfigMap(configMap): { spec+: { reconciling+: { cleanup+: { unknownObjects+: { configMap: configMap } } } } },
          '#withPvc':: d.fn(help='"behavior policy for unknown PVC, Delete by default"', args=[d.arg(name='pvc', type=d.T.string)]),
          withPvc(pvc): { spec+: { reconciling+: { cleanup+: { unknownObjects+: { pvc: pvc } } } } },
          '#withService':: d.fn(help='"behavior policy for unknown Service, Delete by default"', args=[d.arg(name='service', type=d.T.string)]),
          withService(service): { spec+: { reconciling+: { cleanup+: { unknownObjects+: { service: service } } } } },
          '#withStatefulSet':: d.fn(help='"behavior policy for unknown StatefulSet, Delete by default"', args=[d.arg(name='statefulSet', type=d.T.string)]),
          withStatefulSet(statefulSet): { spec+: { reconciling+: { cleanup+: { unknownObjects+: { statefulSet: statefulSet } } } } },
        },
      },
      '#withConfigMapPropagationTimeout':: d.fn(help='"Timeout in seconds for `clickhouse-operator` to wait for modified `ConfigMap` to propagate into the `Pod`\\nMore details: https://kubernetes.io/docs/concepts/configuration/configmap/#mounted-configmaps-are-updated-automatically\\n"', args=[d.arg(name='configMapPropagationTimeout', type=d.T.integer)]),
      withConfigMapPropagationTimeout(configMapPropagationTimeout): { spec+: { reconciling+: { configMapPropagationTimeout: configMapPropagationTimeout } } },
      '#withPolicy':: d.fn(help='"DEPRECATED"', args=[d.arg(name='policy', type=d.T.string)]),
      withPolicy(policy): { spec+: { reconciling+: { policy: policy } } },
    },
    '#templates':: d.obj(help='"allows define templates which will use for render Kubernetes resources like StatefulSet, ConfigMap, Service, PVC, by default, clickhouse-operator have own templates, but you can override it"'),
    templates: {
      '#hostTemplates':: d.obj(help='"hostTemplate will use during apply to generate `clickhose-server` config files"'),
      hostTemplates: {
        '#portDistribution':: d.obj(help='"define how will distribute numeric values of named ports in `Pod.spec.containers.ports` and clickhouse-server configs"'),
        portDistribution: {
          '#withType':: d.fn(help='"type of distribution, when `Unspecified` (default value) then all listen ports on clickhouse-server configuration in all Pods will have the same value, when `ClusterScopeIndex` then ports will increment to offset from base value depends on shard and replica index inside cluster with combination of `chi.spec.templates.podTemlates.spec.HostNetwork` it allows setup ClickHouse cluster inside Kubernetes and provide access via external network bypass Kubernetes internal network"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { type: type },
        },
        '#spec':: d.obj(help=''),
        spec: {
          '#templates':: d.obj(help="\"be careful, this part of CRD allows override template inside template, don't use it if you don't understand what you do\""),
          templates: {
            '#withClusterServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='clusterServiceTemplate', type=d.T.string)]),
            withClusterServiceTemplate(clusterServiceTemplate): { spec+: { templates+: { clusterServiceTemplate: clusterServiceTemplate } } },
            '#withDataVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse data directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='dataVolumeClaimTemplate', type=d.T.string)]),
            withDataVolumeClaimTemplate(dataVolumeClaimTemplate): { spec+: { templates+: { dataVolumeClaimTemplate: dataVolumeClaimTemplate } } },
            '#withHostTemplate':: d.fn(help='"optional, template name from chi.spec.templates.hostTemplates, which will apply to configure every `clickhouse-server` instance during render ConfigMap resources which will mount into `Pod`"', args=[d.arg(name='hostTemplate', type=d.T.string)]),
            withHostTemplate(hostTemplate): { spec+: { templates+: { hostTemplate: hostTemplate } } },
            '#withLogVolumeClaimTemplate':: d.fn(help='"optional, template name from chi.spec.templates.volumeClaimTemplates, allows customization each `PVC` which will mount for clickhouse log directory in each `Pod` during render and reconcile every StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='logVolumeClaimTemplate', type=d.T.string)]),
            withLogVolumeClaimTemplate(logVolumeClaimTemplate): { spec+: { templates+: { logVolumeClaimTemplate: logVolumeClaimTemplate } } },
            '#withPodTemplate':: d.fn(help='"optional, template name from chi.spec.templates.podTemplates, allows customization each `Pod` resource during render and reconcile each StatefulSet.spec resource described in `chi.spec.configuration.clusters`"', args=[d.arg(name='podTemplate', type=d.T.string)]),
            withPodTemplate(podTemplate): { spec+: { templates+: { podTemplate: podTemplate } } },
            '#withReplicaServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each replica inside each shard inside each clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='replicaServiceTemplate', type=d.T.string)]),
            withReplicaServiceTemplate(replicaServiceTemplate): { spec+: { templates+: { replicaServiceTemplate: replicaServiceTemplate } } },
            '#withServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for one `Service` resource which will created by `clickhouse-operator` which cover all clusters in whole `chi` resource"', args=[d.arg(name='serviceTemplate', type=d.T.string)]),
            withServiceTemplate(serviceTemplate): { spec+: { templates+: { serviceTemplate: serviceTemplate } } },
            '#withShardServiceTemplate':: d.fn(help='"optional, template name from chi.spec.templates.serviceTemplates, allows customization for each `Service` resource which will created by `clickhouse-operator` which cover each shard inside clickhouse cluster described in `chi.spec.configuration.clusters`"', args=[d.arg(name='shardServiceTemplate', type=d.T.string)]),
            withShardServiceTemplate(shardServiceTemplate): { spec+: { templates+: { shardServiceTemplate: shardServiceTemplate } } },
            '#withVolumeClaimTemplate':: d.fn(help='"DEPRECATED! VolumeClaimTemplate is deprecated in favor of DataVolumeClaimTemplate and LogVolumeClaimTemplate"', args=[d.arg(name='volumeClaimTemplate', type=d.T.string)]),
            withVolumeClaimTemplate(volumeClaimTemplate): { spec+: { templates+: { volumeClaimTemplate: volumeClaimTemplate } } },
          },
          '#withFiles':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` where this template will apply during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\n"', args=[d.arg(name='files', type=d.T.object)]),
          withFiles(files): { spec+: { files: files } },
          '#withFilesMixin':: d.fn(help='"optional, allows define content of any setting file inside each `Pod` where this template will apply during generate `ConfigMap` which will mount in `/etc/clickhouse-server/config.d/` or `/etc/clickhouse-server/conf.d/` or `/etc/clickhouse-server/users.d/`\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.object)]),
          withFilesMixin(files): { spec+: { files+: files } },
          '#withHttpPort':: d.fn(help='"optional, setup `http_port` inside `clickhouse-server` settings for each Pod where current template will apply\\nif specified, should have equal value with `chi.spec.templates.podTemplates.spec.containers.ports[name=http]`\\nMore info: https://clickhouse.tech/docs/en/interfaces/http/\\n"', args=[d.arg(name='httpPort', type=d.T.integer)]),
          withHttpPort(httpPort): { spec+: { httpPort: httpPort } },
          '#withHttpsPort':: d.fn(help='', args=[d.arg(name='httpsPort', type=d.T.integer)]),
          withHttpsPort(httpsPort): { spec+: { httpsPort: httpsPort } },
          '#withInsecure':: d.fn(help='"optional, open insecure ports for cluster, defaults to \\"yes\\"\\n"', args=[d.arg(name='insecure', type=d.T.string)]),
          withInsecure(insecure): { spec+: { insecure: insecure } },
          '#withInterserverHTTPPort':: d.fn(help='"optional, setup `interserver_http_port` inside `clickhouse-server` settings for each Pod where current template will apply\\nif specified, should have equal value with `chi.spec.templates.podTemplates.spec.containers.ports[name=interserver]`\\nMore info: https://clickhouse.tech/docs/en/operations/server-configuration-parameters/settings/#interserver-http-port\\n"', args=[d.arg(name='interserverHTTPPort', type=d.T.integer)]),
          withInterserverHTTPPort(interserverHTTPPort): { spec+: { interserverHTTPPort: interserverHTTPPort } },
          '#withName':: d.fn(help='"by default, hostname will generate, but this allows define custom name for each `clickhuse-server`"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { name: name } },
          '#withSecure':: d.fn(help='"optional, open secure ports\\n"', args=[d.arg(name='secure', type=d.T.string)]),
          withSecure(secure): { spec+: { secure: secure } },
          '#withSettings':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` where this template will apply during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"', args=[d.arg(name='settings', type=d.T.object)]),
          withSettings(settings): { spec+: { settings: settings } },
          '#withSettingsMixin':: d.fn(help='"optional, allows configure `clickhouse-server` settings inside <yandex>...</yandex> tag in each `Pod` where this template will apply during generate `ConfigMap` which will mount in `/etc/clickhouse-server/conf.d/`\\nMore details: https://clickhouse.tech/docs/en/operations/settings/settings/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='settings', type=d.T.object)]),
          withSettingsMixin(settings): { spec+: { settings+: settings } },
          '#withTcpPort':: d.fn(help='"optional, setup `tcp_port` inside `clickhouse-server` settings for each Pod where current template will apply\\nif specified, should have equal value with `chi.spec.templates.podTemplates.spec.containers.ports[name=tcp]`\\nMore info: https://clickhouse.tech/docs/en/interfaces/tcp/\\n"', args=[d.arg(name='tcpPort', type=d.T.integer)]),
          withTcpPort(tcpPort): { spec+: { tcpPort: tcpPort } },
          '#withTlsPort':: d.fn(help='', args=[d.arg(name='tlsPort', type=d.T.integer)]),
          withTlsPort(tlsPort): { spec+: { tlsPort: tlsPort } },
        },
        '#withName':: d.fn(help='"template name, could use to link inside top-level `chi.spec.defaults.templates.hostTemplate`, cluster-level `chi.spec.configuration.clusters.templates.hostTemplate`, shard-level `chi.spec.configuration.clusters.layout.shards.temlates.hostTemplate`, replica-level `chi.spec.configuration.clusters.layout.replicas.templates.hostTemplate`"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withPortDistribution':: d.fn(help='"define how will distribute numeric values of named ports in `Pod.spec.containers.ports` and clickhouse-server configs"', args=[d.arg(name='portDistribution', type=d.T.array)]),
        withPortDistribution(portDistribution): { portDistribution: if std.isArray(v=portDistribution) then portDistribution else [portDistribution] },
        '#withPortDistributionMixin':: d.fn(help='"define how will distribute numeric values of named ports in `Pod.spec.containers.ports` and clickhouse-server configs"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='portDistribution', type=d.T.array)]),
        withPortDistributionMixin(portDistribution): { portDistribution+: if std.isArray(v=portDistribution) then portDistribution else [portDistribution] },
      },
      '#podTemplates':: d.obj(help='"podTemplate will use during render `Pod` inside `StatefulSet.spec` and allows define rendered `Pod.spec`, pod scheduling distribution and pod zone\\nMore information: https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#spectemplatespodtemplates\\n"'),
      podTemplates: {
        '#podDistribution':: d.obj(help='"define ClickHouse Pod distribution policy between Kubernetes Nodes inside Shard, Replica, Namespace, CHI, another ClickHouse cluster"'),
        podDistribution: {
          '#withNumber':: d.fn(help='"define, how much ClickHouse Pods could be inside selected scope with selected distribution type"', args=[d.arg(name='number', type=d.T.integer)]),
          withNumber(number): { number: number },
          '#withScope':: d.fn(help='"scope for apply each podDistribution"', args=[d.arg(name='scope', type=d.T.string)]),
          withScope(scope): { scope: scope },
          '#withTopologyKey':: d.fn(help='"use for inter-pod affinity look to `pod.spec.affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution.podAffinityTerm.topologyKey`, More info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity"', args=[d.arg(name='topologyKey', type=d.T.string)]),
          withTopologyKey(topologyKey): { topologyKey: topologyKey },
          '#withType':: d.fn(help='"you can define multiple affinity policy types"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { type: type },
        },
        '#withDistribution':: d.fn(help='"DEPRECATED, shortcut for `chi.spec.templates.podTemplates.spec.affinity.podAntiAffinity`"', args=[d.arg(name='distribution', type=d.T.string)]),
        withDistribution(distribution): { distribution: distribution },
        '#withGenerateName':: d.fn(help='"allows define format for generated `Pod` name, look to https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#spectemplatesservicetemplates for details about aviailable template variables"', args=[d.arg(name='generateName', type=d.T.string)]),
        withGenerateName(generateName): { generateName: generateName },
        '#withMetadata':: d.fn(help="\"allows pass standard object's metadata from template to Pod\\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\\n\"", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadata(metadata): { metadata: metadata },
        '#withMetadataMixin':: d.fn(help="\"allows pass standard object's metadata from template to Pod\\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\\n\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadataMixin(metadata): { metadata+: metadata },
        '#withName':: d.fn(help='"template name, could use to link inside top-level `chi.spec.defaults.templates.podTemplate`, cluster-level `chi.spec.configuration.clusters.templates.podTemplate`, shard-level `chi.spec.configuration.clusters.layout.shards.temlates.podTemplate`, replica-level `chi.spec.configuration.clusters.layout.replicas.templates.podTemplate`"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withPodDistribution':: d.fn(help='"define ClickHouse Pod distribution policy between Kubernetes Nodes inside Shard, Replica, Namespace, CHI, another ClickHouse cluster"', args=[d.arg(name='podDistribution', type=d.T.array)]),
        withPodDistribution(podDistribution): { podDistribution: if std.isArray(v=podDistribution) then podDistribution else [podDistribution] },
        '#withPodDistributionMixin':: d.fn(help='"define ClickHouse Pod distribution policy between Kubernetes Nodes inside Shard, Replica, Namespace, CHI, another ClickHouse cluster"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podDistribution', type=d.T.array)]),
        withPodDistributionMixin(podDistribution): { podDistribution+: if std.isArray(v=podDistribution) then podDistribution else [podDistribution] },
        '#withSpec':: d.fn(help='"allows define whole Pod.spec inside StaefulSet.spec, look to https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates for details"', args=[d.arg(name='spec', type=d.T.object)]),
        withSpec(spec): { spec: spec },
        '#withSpecMixin':: d.fn(help='"allows define whole Pod.spec inside StaefulSet.spec, look to https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates for details"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='spec', type=d.T.object)]),
        withSpecMixin(spec): { spec+: spec },
        '#zone':: d.obj(help='"allows define custom zone name and will separate ClickHouse `Pods` between nodes, shortcut for `chi.spec.templates.podTemplates.spec.affinity.podAntiAffinity`"'),
        zone: {
          '#withKey':: d.fn(help='"optional, if defined, allows select kubernetes nodes by label with `name` equal `key`"', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { zone+: { key: key } },
          '#withValues':: d.fn(help='"optional, if defined, allows select kubernetes nodes by label with `value` in `values`"', args=[d.arg(name='values', type=d.T.array)]),
          withValues(values): { zone+: { values: if std.isArray(v=values) then values else [values] } },
          '#withValuesMixin':: d.fn(help='"optional, if defined, allows select kubernetes nodes by label with `value` in `values`"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
          withValuesMixin(values): { zone+: { values+: if std.isArray(v=values) then values else [values] } },
        },
      },
      '#serviceTemplates':: d.obj(help='"allows define template for rendering `Service` which would get endpoint from Pods which scoped chi-wide, cluster-wide, shard-wide, replica-wide level\\n"'),
      serviceTemplates: {
        '#withGenerateName':: d.fn(help='"allows define format for generated `Service` name, look to https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#spectemplatesservicetemplates for details about aviailable template variables"', args=[d.arg(name='generateName', type=d.T.string)]),
        withGenerateName(generateName): { generateName: generateName },
        '#withMetadata':: d.fn(help="\"allows pass standard object's metadata from template to Service\\nCould be use for define specificly for Cloud Provider metadata which impact to behavior of service\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/\\n\"", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadata(metadata): { metadata: metadata },
        '#withMetadataMixin':: d.fn(help="\"allows pass standard object's metadata from template to Service\\nCould be use for define specificly for Cloud Provider metadata which impact to behavior of service\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/\\n\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadataMixin(metadata): { metadata+: metadata },
        '#withName':: d.fn(help='"template name, could use to link inside\\nchi-level `chi.spec.defaults.templates.serviceTemplate`\\ncluster-level `chi.spec.configuration.clusters.templates.clusterServiceTemplate`\\nshard-level `chi.spec.configuration.clusters.layout.shards.temlates.shardServiceTemplate`\\nreplica-level `chi.spec.configuration.clusters.layout.replicas.templates.replicaServiceTemplate` or `chi.spec.configuration.clusters.layout.shards.replicas.replicaServiceTemplate`\\n"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withSpec':: d.fn(help='"describe behavior of generated Service\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/\\n"', args=[d.arg(name='spec', type=d.T.object)]),
        withSpec(spec): { spec: spec },
        '#withSpecMixin':: d.fn(help='"describe behavior of generated Service\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='spec', type=d.T.object)]),
        withSpecMixin(spec): { spec+: spec },
      },
      '#volumeClaimTemplates':: d.obj(help='"allows define template for rendering `PVC` kubernetes resource, which would use inside `Pod` for mount clickhouse `data`, clickhouse `logs` or something else"'),
      volumeClaimTemplates: {
        '#withMetadata':: d.fn(help="\"allows to pass standard object's metadata from template to PVC\\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\\n\"", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadata(metadata): { metadata: metadata },
        '#withMetadataMixin':: d.fn(help="\"allows to pass standard object's metadata from template to PVC\\nMore info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\\n\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='metadata', type=d.T.object)]),
        withMetadataMixin(metadata): { metadata+: metadata },
        '#withName':: d.fn(help='"template name, could use to link inside\\ntop-level `chi.spec.defaults.templates.dataVolumeClaimTemplate` or `chi.spec.defaults.templates.logVolumeClaimTemplate`,\\ncluster-level `chi.spec.configuration.clusters.templates.dataVolumeClaimTemplate` or `chi.spec.configuration.clusters.templates.logVolumeClaimTemplate`,\\nshard-level `chi.spec.configuration.clusters.layout.shards.temlates.dataVolumeClaimTemplate` or `chi.spec.configuration.clusters.layout.shards.temlates.logVolumeClaimTemplate`\\nreplica-level `chi.spec.configuration.clusters.layout.replicas.templates.dataVolumeClaimTemplate` or `chi.spec.configuration.clusters.layout.replicas.templates.logVolumeClaimTemplate`\\n"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withProvisioner':: d.fn(help='"defines `PVC` provisioner - be it StatefulSet or the Operator"', args=[d.arg(name='provisioner', type=d.T.string)]),
        withProvisioner(provisioner): { provisioner: provisioner },
        '#withReclaimPolicy':: d.fn(help='"defines behavior of `PVC` deletion.\\n`Delete` by default, if `Retain` specified then `PVC` will be kept when deleting StatefulSet\\n"', args=[d.arg(name='reclaimPolicy', type=d.T.string)]),
        withReclaimPolicy(reclaimPolicy): { reclaimPolicy: reclaimPolicy },
        '#withSpec':: d.fn(help='"allows define all aspects of `PVC` resource\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\\n"', args=[d.arg(name='spec', type=d.T.object)]),
        withSpec(spec): { spec: spec },
        '#withSpecMixin':: d.fn(help='"allows define all aspects of `PVC` resource\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='spec', type=d.T.object)]),
        withSpecMixin(spec): { spec+: spec },
      },
      '#withHostTemplates':: d.fn(help='"hostTemplate will use during apply to generate `clickhose-server` config files"', args=[d.arg(name='hostTemplates', type=d.T.array)]),
      withHostTemplates(hostTemplates): { spec+: { templates+: { hostTemplates: if std.isArray(v=hostTemplates) then hostTemplates else [hostTemplates] } } },
      '#withHostTemplatesMixin':: d.fn(help='"hostTemplate will use during apply to generate `clickhose-server` config files"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hostTemplates', type=d.T.array)]),
      withHostTemplatesMixin(hostTemplates): { spec+: { templates+: { hostTemplates+: if std.isArray(v=hostTemplates) then hostTemplates else [hostTemplates] } } },
      '#withPodTemplates':: d.fn(help='"podTemplate will use during render `Pod` inside `StatefulSet.spec` and allows define rendered `Pod.spec`, pod scheduling distribution and pod zone\\nMore information: https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#spectemplatespodtemplates\\n"', args=[d.arg(name='podTemplates', type=d.T.array)]),
      withPodTemplates(podTemplates): { spec+: { templates+: { podTemplates: if std.isArray(v=podTemplates) then podTemplates else [podTemplates] } } },
      '#withPodTemplatesMixin':: d.fn(help='"podTemplate will use during render `Pod` inside `StatefulSet.spec` and allows define rendered `Pod.spec`, pod scheduling distribution and pod zone\\nMore information: https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#spectemplatespodtemplates\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podTemplates', type=d.T.array)]),
      withPodTemplatesMixin(podTemplates): { spec+: { templates+: { podTemplates+: if std.isArray(v=podTemplates) then podTemplates else [podTemplates] } } },
      '#withServiceTemplates':: d.fn(help='"allows define template for rendering `Service` which would get endpoint from Pods which scoped chi-wide, cluster-wide, shard-wide, replica-wide level\\n"', args=[d.arg(name='serviceTemplates', type=d.T.array)]),
      withServiceTemplates(serviceTemplates): { spec+: { templates+: { serviceTemplates: if std.isArray(v=serviceTemplates) then serviceTemplates else [serviceTemplates] } } },
      '#withServiceTemplatesMixin':: d.fn(help='"allows define template for rendering `Service` which would get endpoint from Pods which scoped chi-wide, cluster-wide, shard-wide, replica-wide level\\n"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceTemplates', type=d.T.array)]),
      withServiceTemplatesMixin(serviceTemplates): { spec+: { templates+: { serviceTemplates+: if std.isArray(v=serviceTemplates) then serviceTemplates else [serviceTemplates] } } },
      '#withVolumeClaimTemplates':: d.fn(help='"allows define template for rendering `PVC` kubernetes resource, which would use inside `Pod` for mount clickhouse `data`, clickhouse `logs` or something else"', args=[d.arg(name='volumeClaimTemplates', type=d.T.array)]),
      withVolumeClaimTemplates(volumeClaimTemplates): { spec+: { templates+: { volumeClaimTemplates: if std.isArray(v=volumeClaimTemplates) then volumeClaimTemplates else [volumeClaimTemplates] } } },
      '#withVolumeClaimTemplatesMixin':: d.fn(help='"allows define template for rendering `PVC` kubernetes resource, which would use inside `Pod` for mount clickhouse `data`, clickhouse `logs` or something else"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeClaimTemplates', type=d.T.array)]),
      withVolumeClaimTemplatesMixin(volumeClaimTemplates): { spec+: { templates+: { volumeClaimTemplates+: if std.isArray(v=volumeClaimTemplates) then volumeClaimTemplates else [volumeClaimTemplates] } } },
    },
    '#templating':: d.obj(help='"Optional, defines policy for applying current ClickHouseInstallationTemplate to ClickHouseInstallation(s)"'),
    templating: {
      '#withChiSelector':: d.fn(help='"Optional, defines selector for ClickHouseInstallation(s) to be templated with ClickhouseInstallationTemplate"', args=[d.arg(name='chiSelector', type=d.T.object)]),
      withChiSelector(chiSelector): { spec+: { templating+: { chiSelector: chiSelector } } },
      '#withChiSelectorMixin':: d.fn(help='"Optional, defines selector for ClickHouseInstallation(s) to be templated with ClickhouseInstallationTemplate"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='chiSelector', type=d.T.object)]),
      withChiSelectorMixin(chiSelector): { spec+: { templating+: { chiSelector+: chiSelector } } },
      '#withPolicy':: d.fn(help='"When defined as `auto` inside ClickhouseInstallationTemplate, this ClickhouseInstallationTemplate\\nwill be auto-added into ClickHouseInstallation, selectable by `chiSelector`.\\nDefault value is `manual`, meaning ClickHouseInstallation should request this ClickhouseInstallationTemplate explicitly.\\n"', args=[d.arg(name='policy', type=d.T.string)]),
      withPolicy(policy): { spec+: { templating+: { policy: policy } } },
    },
    '#useTemplates':: d.obj(help='"list of `ClickHouseInstallationTemplate` (chit) resource names which will merge with current `Chi` manifest during render Kubernetes resources to create related ClickHouse clusters"'),
    useTemplates: {
      '#withName':: d.fn(help='"name of `ClickHouseInstallationTemplate` (chit) resource"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withNamespace':: d.fn(help='"Kubernetes namespace where need search `chit` resource, depending on `watchNamespaces` settings in `clichouse-operator`"', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { namespace: namespace },
      '#withUseType':: d.fn(help='"optional, current strategy is only merge, and current `chi` settings have more priority than merged template `chit`"', args=[d.arg(name='useType', type=d.T.string)]),
      withUseType(useType): { useType: useType },
    },
    '#withNamespaceDomainPattern':: d.fn(help='"Custom domain pattern which will be used for DNS names of `Service` or `Pod`.\\nTypical use scenario - custom cluster domain in Kubernetes cluster\\nExample: %s.svc.my.test\\n"', args=[d.arg(name='namespaceDomainPattern', type=d.T.string)]),
    withNamespaceDomainPattern(namespaceDomainPattern): { spec+: { namespaceDomainPattern: namespaceDomainPattern } },
    '#withRestart':: d.fn(help="\"In case 'RollingUpdate' specified, the operator will always restart ClickHouse pods during reconcile.\\nThis options is used in rare cases when force restart is required and is typically removed after the use in order to avoid unneeded restarts.\\n\"", args=[d.arg(name='restart', type=d.T.string)]),
    withRestart(restart): { spec+: { restart: restart } },
    '#withStop':: d.fn(help='"Allows to stop all ClickHouse clusters defined in a CHI.\\nWorks as the following:\\n - When `stop` is `1` operator sets `Replicas: 0` in each StatefulSet. Thie leads to having all `Pods` and `Service` deleted. All PVCs are kept intact.\\n - When `stop` is `0` operator sets `Replicas: 1` and `Pod`s and `Service`s will created again and all retained PVCs will be attached to `Pod`s.\\n"', args=[d.arg(name='stop', type=d.T.string)]),
    withStop(stop): { spec+: { stop: stop } },
    '#withTaskID':: d.fn(help='"Allows to define custom taskID for CHI update and watch status of this update execution.\\nDisplayed in all .status.taskID* fields.\\nBy default (if not filled) every update of CHI manifest will generate random taskID\\n"', args=[d.arg(name='taskID', type=d.T.string)]),
    withTaskID(taskID): { spec+: { taskID: taskID } },
    '#withTroubleshoot':: d.fn(help="\"Allows to troubleshoot Pods during CrashLoopBack state.\\nThis may happen when wrong configuration applied, in this case `clickhouse-server` wouldn't start.\\nCommand within ClickHouse container is modified with `sleep` in order to avoid quick restarts\\nand give time to troubleshoot via CLI.\\nLiveness and Readiness probes are disabled as well.\\n\"", args=[d.arg(name='troubleshoot', type=d.T.string)]),
    withTroubleshoot(troubleshoot): { spec+: { troubleshoot: troubleshoot } },
    '#withUseTemplates':: d.fn(help='"list of `ClickHouseInstallationTemplate` (chit) resource names which will merge with current `Chi` manifest during render Kubernetes resources to create related ClickHouse clusters"', args=[d.arg(name='useTemplates', type=d.T.array)]),
    withUseTemplates(useTemplates): { spec+: { useTemplates: if std.isArray(v=useTemplates) then useTemplates else [useTemplates] } },
    '#withUseTemplatesMixin':: d.fn(help='"list of `ClickHouseInstallationTemplate` (chit) resource names which will merge with current `Chi` manifest during render Kubernetes resources to create related ClickHouse clusters"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='useTemplates', type=d.T.array)]),
    withUseTemplatesMixin(useTemplates): { spec+: { useTemplates+: if std.isArray(v=useTemplates) then useTemplates else [useTemplates] } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
